# BigData
Trip_Stats: 3 tasks that involves writing map reduce programs to process trip data. Task 1 consists classifying trips based on distance while calculating different metrics assocaited with each trip using in-mapper combining and state preservation across lines. Task 2 involves implementing k-medoids clustering algorithm to group trips based on location. Task 3 involves writing 3 mapreduce sub-tasks to ount the number of trips for each taxi company, followed by counting and sorting the companies based on total trips

Apache Pig: consist of writing a apache pig script that groups data into regions and their associated gold medals won. Additionally invovles writing a user define function in apahce pig to output visualisation. 

spark-stream:  a spark streaming program using Scala to monitor a folder on HDFS in real-time such that any new
file in the folder will be processed
